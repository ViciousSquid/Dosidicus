<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Decision Engine Documentation</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; }
        code { background-color: #f4f4f4; padding: 2px 4px; border-radius: 4px; }
        .comment { color: #888; font-style: italic; }
        .keyword { font-weight: bold; color: #008080; }
        .string { color: #408080; }
        .function { color: #ff1493; }
    </style>
</head>
<body>

<h1>Decision Engine Documentation</h1>

<p>Below is the extensively documented version of the DecisionEngine class, explaining each part in detail.</p>

<pre><code>
<span class="comment"># Decision engine version 1.0   April 2025</span>

<span class="keyword">import</span> random
<span class="keyword">from</span> .personality <span class="keyword">import</span> Personality

<span class="keyword">class</span> <span class="function">DecisionEngine</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, squid):
        <span class="comment">"""
        Initialize the DecisionEngine with a squid object.

        Parameters:
        - squid: An object representing the squid, containing attributes and methods
                 related to its state and behaviors.
        """</span>
        self.squid = squid

    <span class="keyword">def</span> <span class="function">make_decision</span>(self):
        <span class="comment">"""
        Decision-making process based on the squid's neural network state and current conditions.
        This function aims to simulate decision-making with minimal hardcoding, relying on
        the squid's neural state and active memories.
        """</span>
        <span class="comment"># Gather the current state of the squid</span>
        current_state = {
            <span class="string">"hunger"</span>: self.squid.hunger,
            <span class="string">"happiness"</span>: self.squid.happiness,
            <span class="string">"cleanliness"</span>: self.squid.cleanliness,
            <span class="string">"sleepiness"</span>: self.squid.sleepiness,
            <span class="string">"satisfaction"</span>: self.squid.satisfaction,
            <span class="string">"anxiety"</span>: self.squid.anxiety,
            <span class="string">"curiosity"</span>: self.squid.curiosity,
            <span class="string">"is_sick"</span>: self.squid.is_sick,
            <span class="string">"is_sleeping"</span>: self.squid.is_sleeping,
            <span class="string">"has_food_visible"</span>: <span class="keyword">bool</span>(self.squid.get_visible_food()),
            <span class="string">"carrying_rock"</span>: self.squid.carrying_rock,
            <span class="string">"rock_throw_cooldown"</span>: getattr(self.squid, <span class="string">'rock_throw_cooldown'</span>, 0)
        }

        <span class="comment"># Retrieve the brain network state, which influences emergent behavior</span>
        brain_state = self.squid.tamagotchi_logic.squid_brain_window.brain_widget.state

        <span class="comment"># Collect active memories to influence the decision-making process</span>
        active_memories = self.squid.memory_manager.get_active_memories_data(3)
        memory_influence = {}

        <span class="comment"># Process active memories to determine their influence on the current state</span>
        <span class="keyword">for</span> memory <span class="keyword">in</span> active_memories:
            <span class="keyword">if</span> <span class="keyword">isinstance</span>(memory.get(<span class="string">'raw_value'</span>), dict):
                <span class="keyword">for</span> key, value <span class="keyword">in</span> memory[<span class="string">'raw_value'</span>].items():
                    <span class="keyword">if</span> key <span class="keyword">in</span> memory_influence:
                        memory_influence[key] += value * 0.5  <span class="comment"># Memory influence is half the weight of the current state</span>
                    <span class="keyword">else</span>:
                        memory_influence[key] = value * 0.5

        <span class="comment"># Apply the influence of memories to the current state</span>
        <span class="keyword">for</span> key, value <span class="keyword">in</span> memory_influence.items():
            <span class="keyword">if</span> key <span class="keyword">in</span> current_state <span class="keyword">and</span> <span class="keyword">isinstance</span>(current_state[key], (int, float)):
                current_state[key] = min(100, max(0, current_state[key] + value))

        <span class="comment"># Check for extreme conditions that should override neural decisions</span>
        <span class="keyword">if</span> self.squid.sleepiness >= 95:
            self.squid.go_to_sleep()
            <span class="keyword">return</span> <span class="string">"sleeping"</span>

        <span class="keyword">if</span> self.squid.is_sleeping:
            <span class="keyword">return</span> <span class="string">"sleeping"</span>

        <span class="comment"># Calculate decision weights for each possible action based on the neural state</span>
        decision_weights = {
            <span class="string">"exploring"</span>: brain_state.get(<span class="string">"curiosity"</span>, 50) * 0.8 * (1 - (brain_state.get(<span class="string">"anxiety"</span>, 50) / 100)),
            <span class="string">"eating"</span>: brain_state.get(<span class="string">"hunger"</span>, 50) * 1.2 <span class="keyword">if</span> self.squid.get_visible_food() <span class="keyword">else</span> 0,
            <span class="string">"approaching_rock"</span>: brain_state.get(<span class="string">"curiosity"</span>, 50) * 0.7 <span class="keyword">if</span> <span class="keyword">not</span> self.squid.carrying_rock <span class="keyword">else</span> 0,
            <span class="string">"throwing_rock"</span>: brain_state.get(<span class="string">"satisfaction"</span>, 50) * 0.7 <span class="keyword">if</span> self.squid.carrying_rock <span class="keyword">else</span> 0,
            <span class="string">"avoiding_threat"</span>: brain_state.get(<span class="string">"anxiety"</span>, 50) * 0.9,
            <span class="string">"organizing"</span>: brain_state.get(<span class="string">"satisfaction"</span>, 50) * 0.5
        }

        <span class="comment"># Adjust decision weights based on the squid's personality</span>
        <span class="keyword">if</span> self.squid.personality == Personality.TIMID:
            decision_weights[<span class="string">"avoiding_threat"</span>] *= 1.5
            decision_weights[<span class="string">"approaching_rock"</span>] *= 0.7
        <span class="keyword">elif</span> self.squid.personality == Personality.ADVENTUROUS:
            decision_weights[<span class="string">"exploring"</span>] *= 1.3
            decision_weights[<span class="string">"approaching_rock"</span>] *= 1.2
        <span class="keyword">elif</span> self.squid.personality == Personality.GREEDY:
            decision_weights[<span class="string">"eating"</span>] *= 1.5

        <span class="comment"># Introduce randomness to make the behavior more unpredictable</span>
        <span class="keyword">for</span> key <span class="keyword">in</span> decision_weights:
            decision_weights[key] *= random.uniform(0.85, 1.15)

        <span class="comment"># Determine the best decision based on the highest weight</span>
        best_decision = max(decision_weights, key=decision_weights.get)

        <span class="comment"># Implement the chosen decision</span>
        <span class="keyword">if</span> best_decision == <span class="string">"eating"</span> <span class="keyword">and</span> self.squid.get_visible_food():
            closest_food = min(self.squid.get_visible_food(),
                               key=<span class="keyword">lambda</span> f: self.squid.distance_to(f[0], f[1]))
            self.squid.move_towards(closest_food[0], closest_food[1])
            <span class="keyword">return</span> <span class="string">"moving_to_food"</span>
        <span class="keyword">elif</span> best_decision == <span class="string">"approaching_rock"</span> <span class="keyword">and</span> <span class="keyword">not</span> self.squid.carrying_rock:
            nearby_rocks = [d <span class="keyword">for</span> d <span class="keyword">in</span> self.squid.tamagotchi_logic.get_nearby_decorations(
                self.squid.squid_x, self.squid.squid_y, 150)
                <span class="keyword">if</span> getattr(d, <span class="string">'can_be_picked_up'</span>, <span class="keyword">False</span>)]
            <span class="keyword">if</span> nearby_rocks:
                self.squid.current_rock_target = random.choice(nearby_rocks)
                <span class="keyword">return</span> <span class="string">"approaching_rock"</span>
        <span class="keyword">elif</span> best_decision == <span class="string">"throwing_rock"</span> <span class="keyword">and</span> self.squid.carrying_rock:
            direction = random.choice([<span class="string">"left"</span>, <span class="string">"right"</span>])
            <span class="keyword">if</span> self.squid.throw_rock(direction):
                <span class="keyword">return</span> <span class="string">"throwing_rock"</span>
        <span class="keyword">elif</span> best_decision == <span class="string">"organizing"</span> <span class="keyword">and</span> self.squid.should_organize_decorations():
            <span class="keyword">return</span> self.squid.organize_decorations()
        <span class="keyword">elif</span> best_decision == <span class="string">"avoiding_threat"</span> <span class="keyword">and</span> self.squid.anxiety > 70:
            <span class="comment"># Move away from potential threats</span>
            <span class="keyword">if</span> len(self.squid.tamagotchi_logic.poop_items) > 0:
                self.squid.move_erratically()
            <span class="keyword">return</span> <span class="string">"avoiding_threat"</span>

        <span class="comment"># Default to exploration with varying patterns</span>
        exploration_style = random.choice([<span class="string">"normal"</span>, <span class="string">"slow"</span>, <span class="string">"erratic"</span>])
        <span class="keyword">if</span> exploration_style == <span class="string">"slow"</span>:
            self.squid.move_slowly()
        <span class="keyword">elif</span> exploration_style == <span class="string">"erratic"</span>:
            self.squid.move_erratically()
        <span class="keyword">else</span>:
            self.squid.move_randomly()

        <span class="keyword">return</span> <span class="string">"exploring"</span>
</code></pre>

<h2>Explanation of Key Concepts:</h2>

<ul>
    <li><strong>Neural Network State:</strong> The decision-making process relies heavily on the squid's neural network state, which is influenced by various factors such as hunger, happiness, and curiosity. This state is represented by the <code>brain_state</code> dictionary.</li>
    <li><strong>Memory Influence:</strong> Active memories affect the squid's current state, with each memory having half the weight of the current state. This influence is calculated and applied to the current state.</li>
    <li><strong>Personality Modifiers:</strong> The squid's personality (e.g., timid, adventurous, greedy) modifies the decision weights, making certain actions more or less likely based on the personality trait.</li>
    <li><strong>Randomness:</strong> Randomness is introduced to make the squid's behavior more unpredictable, simulating real-life decision-making where actions are not always deterministic.</li>
    <li><strong>Decision Weights:</strong> Each possible action has a weight calculated based on the neural state and modified by personality and randomness. The action with the highest weight is chosen.</li>
    <li><strong>Extreme Conditions:</strong> Certain conditions, such as high sleepiness, override the neural decisions to ensure the squid's well-being.</li>
</ul>

</body>
</html>
